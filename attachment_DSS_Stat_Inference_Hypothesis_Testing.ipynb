{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Inference and Hypothesis Testing\n",
    "\n",
    "**Statistics** is a science of inference. It is the science of generalization from a part(the randomly chosen sample) to the whole (the population).\n",
    "\n",
    "**Statistical inference** is the process of deducing properties of an underlying distribution by analysis of data. Inferential statistical analysis infers properties about a population: this includes testing hypotheses and deriving estimates.\n",
    "\n",
    "Statistics are helpful in analyzing most collections of data. **Hypothesis testing** can justify conclusions even when no\n",
    "scientific theory exists.\n",
    "\n",
    "## Average Experience of Data Science Specialization(DSS) batch with Statistical Inference\n",
    "We will aim to study how accurately can we characterize the actual average participant experience (population mean) from the samples of data (sample mean). We can quantify the certainity of outcome through the confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Let us explore the original data\n",
    "\n",
    "dss_exp = np.array([12,  15,  13,  20,  19,  20,  11,  19,  11,  12,  19,  13,  \n",
    "                    12,  10,  6,  19,  3,  1,  1,  0,  4,  4,  6,  5,  3,  7,  \n",
    "                    12,  7,  9,  8,  12,  11,  11,  18,  19,  18,  19,  3,  6,  \n",
    "                     5,  6,  9,  11,  10,  14,  14,  16,  17,  17,  19,  0,  2,  \n",
    "                     0,  3,  1,  4,  6,  6,  8,  7,  7,  6,  7,  11,  11,  10,  \n",
    "                    11,  10,  13,  13,  15,  18,  20,  19,  1,  10,  8,  16,  \n",
    "                    19,  19,  17,  16,  11,  1,  10,  13,  15,  3,  8,  6,  9,  \n",
    "                    10,  15,  19,  2,  4,  5,  6,  9,  11,  10,  9,  10,  9,  \n",
    "                    15,  16,  18,  13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Underlying distribution of Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of Experience\n",
    "plt.hist(dss_exp, range = (0,20), bins = 21)\n",
    "# Add axis labels\n",
    "plt.xlabel(\"Experience in years\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Experience in Data Science Specialization\")\n",
    "plt.axvline(x=dss_exp.mean(), linewidth=2, color = 'r') # Draws the red vertical line in graph at the average experience\n",
    "plt.show()\n",
    "\n",
    "# Statistics of DSS Batch experience\n",
    "print(\"Mean Experience of DSS Batch: {:4.3f}\".format(dss_exp.mean()))\n",
    "print(\"Std Deviation of Experience of DSS Batch: {:4.3f}\".format(dss_exp.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters for sampling\n",
    "n = 10\n",
    "NUM_TRIALS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating DSS Experience from samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just try for 1 iteration\n",
    "\n",
    "samp = np.random.choice(dss_exp, size = n, replace = True)\n",
    "samp_mean = samp.mean()\n",
    "samp_sd = samp.std()\n",
    "print(\"Samp_mean = {:4.3f} Sample_SD = {:4.3f}\".format(samp_mean, samp_sd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp # Display the sample values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How will the distribution of Sample Mean look like\n",
    "\n",
    "We are now drawing samples for 1000 times (NUM_TRIALS) and compute the mean each time. The distribution is plotted to identify range of values it can take. The original data has experience raging between 0 years and 20 years and spread across it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Distribution of Sample means\n",
    "\n",
    "np.random.seed(100)\n",
    "mn_array = np.zeros(NUM_TRIALS)\n",
    "sd_array = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Extract Random Samples and compute mean & standard deviation\n",
    "for i in range(NUM_TRIALS):\n",
    "  samp = np.random.choice(dss_exp, size = n, replace = True)\n",
    "  mn_array[i] = samp.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate the distribution - Not important for understanding\n",
    "mn = mn_array.mean()\n",
    "sd = mn_array.std()\n",
    "x5_pct = np.percentile(mn_array, 5.0)\n",
    "x95_pct = np.percentile(mn_array, 95.0)\n",
    "print(\"Mean = {:4.3f}, Std Dev = {:4.3f}, 5% Pct = {:4.3f}, 95% Pct = {:4.3f}\".format(mn, sd, x5_pct, x95_pct))\n",
    "\n",
    "\n",
    "# Plot Sampling distribution of Mean    \n",
    "plt.hist(mn_array, range=(0,20), bins = 41)\n",
    "# Add axis labels\n",
    "plt.xlabel(\"Avg Experience with n={}\".format(n))\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Sampling Distribution of Mean\")\n",
    "plt.axvline(x=x5_pct, linewidth=2, color = 'r')\n",
    "plt.axvline(x=x95_pct, linewidth=2, color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Central Limit Theorem\n",
    "\n",
    "The original experience of students of Data science is in no way appears to be normal distribution.` It has peaks around 5 years, 10 years and 19 years experience.\n",
    "\n",
    "The above plot is histogram of mean of samples for any given *n*. As you vary *n* from 1 to 128 you will see the following summary for the **Sampling Distribution of Mean** chart. The code for creating the below table is in the **Appendix Code 3** section. \n",
    "\n",
    "- n =   1, Mean = 10.301, Std Dev = 5.689, 5% Pct = 1.000, 95% Pct = 19.000\n",
    "- n =   2, Mean = 10.431, Std Dev = 3.984, 5% Pct = 4.000, 95% Pct = 17.000\n",
    "- n =   4, Mean = 10.388, Std Dev = 2.878, 5% Pct = 5.500, 95% Pct = 15.000\n",
    "- n =   8, Mean = 10.407, Std Dev = 2.031, 5% Pct = 7.000, 95% Pct = 13.875\n",
    "- n =  10, Mean = 10.455, Std Dev = 1.794, 5% Pct = 7.600, 95% Pct = 13.405\n",
    "- n =  16, Mean = 10.467, Std Dev = 1.372, 5% Pct = 8.188, 95% Pct = 12.688\n",
    "- n =  32, Mean = 10.470, Std Dev = 0.984, 5% Pct = 8.844, 95% Pct = 12.125\n",
    "- n =  64, Mean = 10.446, Std Dev = 0.693, 5% Pct = 9.297, 95% Pct = 11.609\n",
    "- n = 128, Mean = 10.451, Std Dev = 0.502, 5% Pct = 9.625, 95% Pct = 11.258\n",
    "\n",
    "One important point is to note the **trend in values of Std Dev in the above table as *n* increases**.\n",
    "\n",
    "- n = 2 : Std Dev = 3.984 ~ 5.665/$\\sqrt2$  where 5.665 is the standard deviation of the experience of the class (population std. dev)\n",
    "- n = 4 : Std Dev = 2.878 ~ 5.665/$\\sqrt4$\n",
    "- n = 10 : Std Dev = 1.794 ~ 5.665/$\\sqrt10$\n",
    "- and so on ...\n",
    "\n",
    "As *n* increases the Std Dev of *Sampling distribution of Mean* reduces from 5.689 (n = 1) to 0.502 (n = 128). As n increases the *Sampling distribution of Mean* looks more normal. **It is observed that when n >= 30 irrespective of the original distribution the Sampling distribution of Mean becomes normal distribution.**\n",
    "\n",
    "![Sampling Mean evolves to normal distribution](http://flylib.com/books/2/528/1/html/2/images/figu115_1.jpg)\n",
    "\n",
    "\n",
    "This has profound implications for statistical inference and because of this specific phenomenan we can quantify the certainity of the outcome. Without this result it is impossible to quantify the confidence interval of the sample mean.\n",
    "\n",
    "To interpret alternatively if one takes 16 random samples from the data, it is likely that the average of 16 values will lie with 8.188 and 12.688 for 90% of the times.\n",
    "\n",
    "### Definition of Central Limit Theorem\n",
    "\n",
    "In probability theory, the central limit theorem (CLT) establishes that, for the most commonly studied scenarios, when independent random variables are added, their sum tends toward a **normal distribution** (commonly known as a bell curve) even if the original variables themselves are not normally distributed [Ref: Wikipedia]\n",
    "\n",
    "The key point to note is that irrespective of the original distribution then sum (and hence average as well) of large samples tend towards normal distribution. This gives power to estimate the confidence intervals.\n",
    "\n",
    "\n",
    "### Properties of Normal Distribution\n",
    "\n",
    "Normal disribution has following characteristics\n",
    "\n",
    "![Normal Distribution](http://flylib.com/books/2/528/1/html/2/images/figu114_1.jpg)\n",
    "\n",
    "- ~68.3% of values lie within 1 Standard Deviation\n",
    "- ~90.0% of values lie within 1.645 Standard Deviations\n",
    "- ~95.0% of values lie within 1.96 Standard Deviations\n",
    "- ~95.5% of values lie within 2 Standard Deviations\n",
    "- ~99.7% of values lie within 3 Standard Deviations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to check if the true mean lies within 90% Confidence Interval\n",
    "\n",
    "def samp_mean_within_ci(mn, l_5pct, u_95pct):\n",
    "    out = True\n",
    "    if (mn < l_5pct) | (mn > u_95pct):\n",
    "        out = False\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the average experience estimate from sample and Confidence Intervals\n",
    "\n",
    "Now given the sample size *n* we can estimate the sample mean and confidence interval. The confidence interval is estimated assuming normal distribution which really holds good when n >= 30.\n",
    "\n",
    "When n is increased the confidence interval becomes smaller which implies that results are obtained with higher certainity.\n",
    "\n",
    "**Execute the code below multiple times and check how often the population mean of 10.435 will lie within 90% confidence interval. It should be on average 9 out of 10 times i.e 90% **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation and Confidence Interval\n",
    "#np.random.seed(100) # seed value is set to reproduce the results\n",
    "\n",
    "samp = np.random.choice(dss_exp, size = n, replace = True)\n",
    "samp_mean = samp.mean()\n",
    "samp_sd = samp.std()\n",
    "sd_ci = samp_sd/np.sqrt(n) #  divided by sqrt(n) is done so as to compensate for the reduction in std. dev due to sample size of n\n",
    "\n",
    "samp_lower_5pct = samp_mean - 1.645 * sd_ci # Lower 90% confidence interval (This is approximate version to build intution)\n",
    "samp_upper_95pct = samp_mean + 1.645 * sd_ci # Upper 90% confidence interval (This is approximate version to build intution)\n",
    "\n",
    "print(\"Pop Mean: {:4.3f} | Sample: L_5PCT = {:4.3f} | M = samp_mean = {:4.3f}  | H_95PCT = {:4.3f}\".format(dss_exp.mean(), samp_lower_5pct, samp_mean, samp_upper_95pct))\n",
    "\n",
    "# Checking if the population mean lies within 90% Confidence Interval (CI)\n",
    "mn_within_ci_flag = samp_mean_within_ci(dss_exp.mean(), samp_lower_5pct, samp_upper_95pct)\n",
    "print(\"True mean lies with the 90% confidence Intervel = {}\".format(mn_within_ci_flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "A statistical hypothesis, sometimes called confirmatory data analysis, is a hypothesis that is testable on the basis of observing a process that is modeled via a set of random variables.[1] A statistical hypothesis test is a method of statistical inference. Commonly, two statistical data sets are compared, or a data set obtained by sampling is compared against a synthetic data set from an idealized model. A hypothesis is proposed for the statistical relationship between the two data sets, and this is compared as an alternative to an idealized null hypothesis that proposes no relationship between two data sets. The comparison is deemed statistically significant if the relationship between the data sets would be an unlikely realization of the null hypothesis according to a threshold probabilityâ€”the significance level. Hypothesis tests are used in determining what outcomes of a study would lead to a rejection of the null hypothesis for a pre-specified level of significance. The process of distinguishing between the null hypothesis and the alternative hypothesis is aided by identifying two conceptual types of errors (type 1 & type 2), and by specifying parametric limits on e.g. how much type 1 error will be permitted. [Ref: Wikipedia]\n",
    "\n",
    "Let us define the Hypotheses as follows:\n",
    "- **H0** : Average Experience of Current Batch & Previous batch are **same**\n",
    "- **H1** : Average Experience of Current Batch & Previous batch are **different**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Previous Batch Data for working experience\n",
    "dss_exp_prev = np.array([1, 14,  6,  7, 10, 10, 19, 15, 19, 15, \n",
    "                    2,  2, 14, 14, 14,  3,  0,  4, 11,  7, \n",
    "                    1,  2,  0,  1,  2,  2,  2,  1,  1,  2, \n",
    "                    4,  4,  3,  3,  3,  3,  4,  3,  3,  7, \n",
    "                    8,  6,  6,  6,  7, 8, 8, 8, 8, 7, \n",
    "                    8, 0, 0, 7, 6, 9, 10, 9, 9, 11, \n",
    "                    11, 9, 10, 10, 11, 10, 11, 9, 9, 9, \n",
    "                    12, 14, 13, 14, 18, 14, 11, 10, 17, 20, \n",
    "                    18, 5, 13, 4, 2, 4, 3, 12, 12, 14, \n",
    "                    12, 12, 10, 14, 4, 11, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_exp_prev = dss_exp_prev.mean()\n",
    "std_exp_prev = dss_exp_prev.std()\n",
    "print(\"Previous DSS Batch: Avg Exp - {:4.3f} Std Dev - {:4.3f}\".format(avg_exp_prev, std_exp_prev))\n",
    "\n",
    "plt.hist(dss_exp_prev, range=(0,20), bins = 21)\n",
    "plt.axvline(x=dss_exp_prev.mean(), linewidth=2, color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "n = 20\n",
    "\n",
    "dss_mean = dss_exp.mean()\n",
    "dss_sd   = dss_exp.std()\n",
    "print(\"Current DSS Batch : Population Mean - {:4.3f}\".format(dss_mean))\n",
    "\n",
    "dss_prev_samp = np.random.choice(dss_exp_prev, size = n, replace = True)\n",
    "dss_prev_samp_mean = dss_prev_samp.mean()\n",
    "print(\"Previous DSS Batch Sample Mean: {:4.3f}\".format(dss_prev_samp_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "t_statistic = (dss_prev_samp_mean - dss_mean)/(dss_sd/np.sqrt(n))\n",
    "p_val = 2 * stats.t.cdf(t_statistic, df= (n-1))\n",
    "print(\"T-Statistic : {:4.2f}, p-Value = {:4.2f}\".format(t_statistic,p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Above code describes to do hypothesis testing based on the intuition from Sampling distribution of mean. There will be differences with exact math based on various conditions and assumptions made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Code\n",
    "\n",
    "Set of codes used for reference or detailed info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix Code 1\n",
    "\n",
    "Show the frequency distribution of experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(dss_exp)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix Code 2\n",
    "\n",
    "Code for dumping the experiment results to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create random samples to check if the true mean lie within the specified confidence Interval\n",
    "\n",
    "samp_mn_vec, lower_5pct, upper_95pct, flag_true_mean_within_ci = (np.zeros(NUM_TRIALS), np.zeros(NUM_TRIALS), np.zeros(NUM_TRIALS), np.zeros(NUM_TRIALS))\n",
    "for i in range(NUM_TRIALS):\n",
    "    samp = np.random.choice(dss_exp, size = n, replace = True)\n",
    "    samp_mn_vec[i] = samp.mean()\n",
    "    samp_sd = samp.std()\n",
    "    sd_ci = samp_sd/np.sqrt(n)\n",
    "    lower_5pct[i] = samp_mn_vec[i] - 1.645 * sd_ci\n",
    "    upper_95pct[i] = samp_mn_vec[i] + 1.645 * sd_ci\n",
    "    flag_true_mean_within_ci[i] = int(samp_mean_within_ci(dss_exp.mean(), lower_5pct[i], upper_95pct[i]))\n",
    "    #print(x5_pct, samp_mn_vec[i], x95_pct, lower_5pct[i], upper_95pct[i], flag_true_mean_within_ci[i])\n",
    "    \n",
    "df = pd.DataFrame(np.column_stack((samp_mn_vec,lower_5pct,upper_95pct, flag_true_mean_within_ci)), columns = ['samp_mean', 'lower_5pct', 'upper_95pct', 'flag_true_mean_within_ci' ])    \n",
    "df.to_csv('expt_n{}_iters{}.csv'.format(n, NUM_TRIALS)) \n",
    "\n",
    "# The results may slightly deviate due to fact that the distribution may not be a perfect normal distribution and randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix Code 3\n",
    "\n",
    "Demonstrate how the standard deviation of sample mean reduce and the distribution goes closer to normal distribution.\n",
    "The results are used in the table above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Sample means for various values\n",
    "n_list = [1,2,4,8,10,16,32,64,128]\n",
    "\n",
    "for n in n_list:\n",
    "    np.random.seed(100)\n",
    "\n",
    "    mn_array = np.zeros(NUM_TRIALS)\n",
    "    sd_array = np.zeros(NUM_TRIALS)\n",
    "\n",
    "    # Extract Random Samples and compute mean & standard deviation\n",
    "    for i in range(NUM_TRIALS):\n",
    "        samp = np.random.choice(dss_exp, size = n, replace = True)\n",
    "        mn_array[i] = samp.mean()\n",
    "    \n",
    "    # Annotate the distribution - Not important for understanding\n",
    "    mn = mn_array.mean()\n",
    "    sd = mn_array.std()\n",
    "    x5_pct = np.percentile(mn_array, 5.0)\n",
    "    x95_pct = np.percentile(mn_array, 95.0)\n",
    "    print(\" n = {}, Mean = {:4.3f}, Std Dev = {:4.3f}, 5% Pct = {:4.3f}, 95% Pct = {:4.3f}\".format(n, mn, sd, x5_pct, x95_pct))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix Code 4 : Stats functions for Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2-tailed hypothesis testing \n",
    "# Ref: http://www.scipy-lectures.org/packages/statistics/index.html#hypothesis-testing-comparing-two-groups\n",
    "from scipy import stats\n",
    "dss_exp_prev_samp = np.random.choice(dss_exp_prev, size = 20, replace = True)\n",
    "dss_exp_samp = np.random.choice(dss_exp, size = 20, replace = True)\n",
    "stats.ttest_ind(dss_exp_prev_samp, dss_exp_samp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
